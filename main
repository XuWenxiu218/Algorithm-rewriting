import numpy
import pprint
import cts
import id2word
from scipy.special import polygamma
from scipy.special import gammaln, psi
from gensim import interfaces, utils, matutils, _matutils
import pandas as pd
from compute_likelihood import compute_likelihood
from  doc_e_step import doc_e_step
from opt_alpha import opt_alpha
from gensim.matutils import (
    kullback_leibler, hellinger, jaccard_distance, jensen_shannon,
    dirichlet_expectation, logsumexp, mean_absolute_difference
)
formatted=True
def main():
    doc_num = 20
    topic_num = 5
    converged = 0
    a=0.2
    #alpha = numpy.array([0.2, 0.2, 0.2, 0.2, 0.2])  # number_topic
    nt = numpy.array([37.6, 37.6, 37.6, 37.6, 37.6])
    gamma = numpy.array([37.8, 37.8, 37.8, 37.8, 37.8])  # sum(phi)+alpha,初始化gamma
    # gamma = alpha + nt  #初始化phi
    #beta = pd.read_excel('变分1.xlsx', sheetname='Sheet4')
    #beta = numpy.array(beta)
    beta=numpy.random.rand(1031,5)
    id2word = pd.read_excel('id2words.xlsx', sheetname='Sheet2')
    id2word = numpy.array(id2word)
    alpha_suffstats = 0
    gammas = numpy.zeros((5, 1))
    betas = numpy.zeros((1031, 5))
    gamma_m = numpy.zeros((20, 5))
    class_word = numpy.zeros((1031, 5))
    VAR_MAX_ITER = 100
    likelihood_sum=0.1
    for iter in range(VAR_MAX_ITER):
        likelihood_old_sum=0
        for d in range(20):
            likelihood = 0.1
            id2words = id2word[:, d]
            likelihood_e, gamma, phi, doc_sum_phi = doc_e_step(a, beta, gamma, likelihood, id2words)
            doc_psi_sum_gamma = psi(gamma.sum(axis=0))
            doc_sum_psi_gamma = psi(gamma).sum(axis=0)
            al_suuf = doc_sum_psi_gamma - doc_psi_sum_gamma
            alpha_suffstats += al_suuf
            likelihood_old_sum += likelihood_e
            class_word += doc_sum_phi
        print(likelihood_old_sum)
        m_opt_alpha = opt_alpha(alpha_suffstats, 20, 5)
        class_total_1 = class_word.sum(axis=0)
        # 归一化Beta
        class_total = numpy.zeros((1031, 5))
        for v in range(1031):
            class_total = numpy.array(class_total_1)
        log_beta = numpy.log(class_word) - numpy.log(class_total)
        beta=numpy.exp(log_beta)
        a = opt_alpha(alpha_suffstats, 20, 5)
        converged = (likelihood_sum - likelihood_old_sum) / likelihood_sum
        a=likelihood_old_sum
        likelihood_sum =a
        print('converged:',converged)
        if abs(converged) < 1e-4:
            print('迭代后的值小于1e-4了！，整体迭代完毕', converged, '此时迭代了', iter, '次')
            break
    return beta
shown=[]
beta=main()
read_excel_file = r'参数.xlsx'
excel_title=['word','id']
id2words=id2word.excel_to_dict(read_excel_file,excel_title)
for i in range(5):
    list=[]
    topic_=beta[:,i]
    bestn = matutils.argsort(topic_, 20, reverse=True)
    print('bestn:::;;', bestn)
    topic_ = [(id2words[id], topic_[id]) for id in bestn]
    for k, v in topic_:
        list.append(k)
        #print(list)
    if formatted:
        topic_ = ' + '.join(['%.3f*"%s"' % (v, k) for k, v in topic_])
    shown.append((i, topic_))
print(shown)
print('a')
